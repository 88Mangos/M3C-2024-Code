{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Other Constants\n",
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a weighting function (e.g., linear decay)\n",
    "def weight_function(t, decay_rate=0.1):\n",
    "    return np.exp(-decay_rate * t)\n",
    "\n",
    "# Estimate Probability Density Function\n",
    "def estimate_pdf(data_points):\n",
    "    weights = weight_function(np.arange(len(data_points)))\n",
    "    weights /= weights.sum()\n",
    "    # Perform kernel density estimation\n",
    "    kde = gaussian_kde(data_points,weights=weights)\n",
    "    return kde\n",
    "\n",
    "def predict(city):\n",
    "    data = pd.read_excel(\"data.xlsx\", sheet_name=city)\n",
    "\n",
    "    years = np.array(data.Year[0:20]) # -> running from 2002 to 2022\n",
    "    # Standardize years such that 2002 is the zeroth year.\n",
    "    years = years - 2002\n",
    "    # print(years)\n",
    "    # print(years.shape)\n",
    "    # Starting from 2024, we want to go to 2074. 2023 is Index 21, so 2024 is index 22. That means 2017 is Index 72,\n",
    "\n",
    "    data_points = np.array(data.Ratio[0:20])\n",
    "    data_2023 = np.array(data.Ratio[21]) # Set aside for error checking\n",
    "\n",
    "    if (city == 'Brighton'):\n",
    "        scaling = (1/100.0)\n",
    "    elif (city == 'Manchester'):\n",
    "        scaling = (1/10.0)\n",
    "    data_points = data_points / scaling\n",
    "    # Create Plot to display Kernel Estimation\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    x_values = np.linspace(min(data_points), max(data_points), 1000)\n",
    "    plt.hist(data_points, bins=30, density=True, alpha=0.5, label='Histogram')\n",
    "    plt.plot(x_values, estimate_pdf(data_points)(x_values), label='Kernel Density Estimation')\n",
    "    plt.title('Initial Kernel Density Estimation')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.legend()\n",
    "\n",
    "    # go to 2074\n",
    "    for i in np.arange(1,54): \n",
    "        # Add the current year into years array\n",
    "        curr_year = years.shape[0]\n",
    "        prev_year = curr_year - 1\n",
    "        years = np.append(years, curr_year)\n",
    "        # Compute probability density functions and perform Monte Carlo Simulation\n",
    "        kde = estimate_pdf(data_points) # Generate probability distribution\n",
    "        kde_samples = kde.resample(size=N) # Sample from the pdf\n",
    "\n",
    "        compare_to_prev_year = kde_samples - data_points[prev_year]\n",
    "        # Find the mean deviation from the previous year's value. If the value is negative, we will subtract our adjustment factor. If positive, add it.\n",
    "        multiplier = scaling\n",
    "        if (np.mean(compare_to_prev_year) < 0):\n",
    "            multiplier = -multiplier\n",
    "        \n",
    "        adjustment_factor = np.sqrt(np.sum(np.square(compare_to_prev_year))/N)\n",
    "        adjustment_factor = adjustment_factor*multiplier\n",
    "        adjustment_factor = np.log(adjustment_factor)\n",
    "\n",
    "        # Randomly sample a value from the distribution and add the adjustment factor.\n",
    "        curr_year_point = np.mean(kde.resample(5)) #+ adjustment_factor\n",
    "        data_points = np.append(data_points, curr_year_point)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    x_values = np.linspace(min(data_points), max(data_points), 1000)\n",
    "    plt.hist(data_points, bins=30, density=True, alpha=0.5, label='Histogram')\n",
    "    plt.plot(x_values, estimate_pdf(data_points)(x_values), label='Kernel Density Estimation')\n",
    "    plt.title('Final Kernel Density Estimation')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    data_points = data_points * scaling\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(years,data_points)\n",
    "    plt.vlines(21, np.min(data_points), np.max(data_points), colors='red')\n",
    "    plt.xlabel(\"Years since 2002\")\n",
    "    plt.ylabel(\"Median Income/Average Home Price Ratio\")\n",
    "    plt.title(\"Change in Median Income/Average Home Price Ratio\")\n",
    "\n",
    "    # Evaluate Percent Error\n",
    "    p_e = np.abs(data_points[21]-data_2023)/data_2023*100\n",
    "    print(f'Percent Error: {p_e}')\n",
    "\n",
    "    \n",
    "    years = years + 2002\n",
    "    data = {\n",
    "        'Year': years,\n",
    "        'Ratio': data_points\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(f\"Q3_predictions_{city}.xlsx\", sheet_name=city)\n",
    "    return p_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('Brighton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('Manchester')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
